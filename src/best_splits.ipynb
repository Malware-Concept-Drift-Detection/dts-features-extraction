{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train-Test splits\n",
    "\n",
    "- In this notebook the approach is changed. Instead of implementing equidistant splits of 1 month or day, the splits are now determined by the percentage length of the training set. Ultimately, a timestamp $t$ is calculated, designating data before $t$ as the training set and data at and after $t$ as the testing set.\n",
    "- Three splits are computed in total:\n",
    "    - 50%-50% Training-Test: This setting maximizes the number of new appearing families in the testing set while ensuring a minimum amount of data points for the training set.\n",
    "    - 70%-30% Training-Test: In this split, a significant percentage of the training set is favored, with less concern about the number of new appearing families in the testing set.\n",
    "    - 62.33%-37.67% Training-Test: An objective function is constructed to maximize both the train-test balancing (linearly favoring splits as the percentage approaches 70%) and the number of appearing families in the testing set. The identified split represents a trade-off between these two scores.\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa8908488b823c9b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from utils.best_split_utils import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:46:07.841726806Z",
     "start_time": "2024-03-11T13:46:07.799312109Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              sha256  first_submission_date   \n0  98f8e26e12b978102fa39c197f300ebe5fe535617737d5...             1630575593  \\\n1  7b2999ffadbc3b5b5c5e94145ca4e2f8de66ac1e3ddd52...             1629375559   \n2  e7569d494fe00be04ef6c9fcc5e54720c0df623b08e79d...             1362057319   \n3  1ed60c04f572b6acb9f64c31db55ef5c6b5465bd4da1eb...             1630624233   \n4  4c4aaff20a57213d9a786e56ad22f1eaa94694a2f1042b...             1592186154   \n\n     family  \n0     tnega  \n1    quasar  \n2     pasta  \n3    cjishu  \n4  kingsoft  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sha256</th>\n      <th>first_submission_date</th>\n      <th>family</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>98f8e26e12b978102fa39c197f300ebe5fe535617737d5...</td>\n      <td>1630575593</td>\n      <td>tnega</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7b2999ffadbc3b5b5c5e94145ca4e2f8de66ac1e3ddd52...</td>\n      <td>1629375559</td>\n      <td>quasar</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e7569d494fe00be04ef6c9fcc5e54720c0df623b08e79d...</td>\n      <td>1362057319</td>\n      <td>pasta</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1ed60c04f572b6acb9f64c31db55ef5c6b5465bd4da1eb...</td>\n      <td>1630624233</td>\n      <td>cjishu</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4c4aaff20a57213d9a786e56ad22f1eaa94694a2f1042b...</td>\n      <td>1592186154</td>\n      <td>kingsoft</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the merged malware data\n",
    "df = pd.read_csv(\"vt_reports/merge.csv\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:46:07.963195087Z",
     "start_time": "2024-03-11T13:46:07.841527528Z"
    }
   },
   "id": "fde28e3017ef7755"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fsd = \"first_submission_date\"\n",
    "# Convert the timestamps to datetime format\n",
    "df_dt = df.copy()\n",
    "df_dt[fsd] = df_dt[fsd].apply(lambda t: pd.to_datetime(t, unit='s'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:46:09.668071715Z",
     "start_time": "2024-03-11T13:46:07.952604855Z"
    }
   },
   "id": "1cee3dba0ab24b0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Choose the Train-Test split by choosing Training set length\n",
    "\n",
    "Given the length in % of the training set, the dataset it split by the time axis using the bisection method."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39d46371d04b4b1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_balanced_split(timestamps, training_perc):\n",
    "    low, high = 0, len(timestamps) - 1\n",
    "    idx = - 1\n",
    "    while low <= high:\n",
    "        mid = (low + high) // 2\n",
    "        mid_value = timestamps[mid]\n",
    "        perc_train = len(df_dt[df_dt[fsd] < mid_value]) / len(df_dt)\n",
    "        if perc_train == training_perc:\n",
    "            idx = mid\n",
    "            high = mid - 1\n",
    "        elif perc_train < training_perc:\n",
    "            # Search in the right half\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            # Search in the left half\n",
    "            high = mid - 1\n",
    "\n",
    "    return timestamps[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:46:09.670646654Z",
     "start_time": "2024-03-11T13:46:09.670455983Z"
    }
   },
   "id": "1c87a7814db78c4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_bs_af(df: pd.DataFrame, ref_df: pd.DataFrame, date_split: pd.Timestamp,\n",
    "                    bs_f: Callable = lambda x: 1 - np.abs(x - 0.7) / 0.7):\n",
    "    # Train-Test balancing: this score increases as the training test length\n",
    "    # in % is approaching 80% of the samples\n",
    "    train_prop = len(df[df[fsd] < date_split]) / len(ref_df)\n",
    "    bs = bs_f(train_prop)\n",
    "\n",
    "    # % Appearing families in testing set\n",
    "    df_train_nonzero = split_and_group_nonzero(src_df=df, split_condition=df[fsd] < date_split)\n",
    "    df_test_nonzero = split_and_group_nonzero(src_df=df, split_condition=df[fsd] >= date_split)\n",
    "\n",
    "    test_families = df_test_nonzero[\"family\"].unique()\n",
    "    af = ((len(test_families) - len(np.intersect1d(df_train_nonzero[\"family\"].unique(), test_families))) /\n",
    "          len(ref_df[\"family\"].unique()))\n",
    "\n",
    "    return {\"bs\": bs, \"af\": af}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:46:09.673455639Z",
     "start_time": "2024-03-11T13:46:09.671550743Z"
    }
   },
   "id": "a95d44f580a6070d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def max_train_from_new_f(splits):\n",
    "    ref_df_dt = df_dt.copy()\n",
    "    af_f = lambda s: compute_bs_af(df_dt, ref_df_dt, s)[\"af\"]\n",
    "    ref_af = af_f(splits[0])\n",
    "    for i in range(1, len(splits)):\n",
    "        if af_f(splits[i]) < ref_af:\n",
    "            return splits[i - 1]\n",
    "    return splits[len(splits) - 1]\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:46:09.673817489Z",
     "start_time": "2024-03-11T13:46:09.673721030Z"
    }
   },
   "id": "3029190f1b130253"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_unique = df_dt[fsd].sort_values().unique()\n",
    "t_best_split = find_balanced_split(t_unique, 0.7)\n",
    "print_statistics(df_dt, t_best_split, f\"Split at {t_best_split}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:46:09.725246545Z",
     "start_time": "2024-03-11T13:46:09.714847301Z"
    }
   },
   "id": "9b956bd13645f846"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_unique = df_dt[fsd].sort_values().unique()\n",
    "t_split = find_balanced_split(t_unique, 0.5)\n",
    "date_splits = [t for t in t_unique if t >= t_split]\n",
    "t_min_split = max_train_from_new_f(date_splits)\n",
    "print_statistics(df_dt, t_min_split, f\"Split at {t_min_split}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T13:46:09.715071008Z"
    }
   },
   "id": "23e661c5224f560c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date_splits = [t for t in t_unique if t_min_split <= t <= t_best_split]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T13:46:09.715260710Z"
    }
   },
   "id": "578b8f33fa314adc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_scores, df_ref_scores = df_dt.copy(), df_dt.copy()\n",
    "js_scores, perc_app_families, balance_scores = [], [], []\n",
    "for date_split in date_splits:\n",
    "    scores = compute_bs_af(df=df_scores, ref_df=df_ref_scores, date_split=date_split)\n",
    "    perc_app_families.append(scores[\"af\"])\n",
    "    balance_scores.append(scores[\"bs\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T13:46:09.715411135Z"
    }
   },
   "id": "11faf26e15600c38"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "perc_app_families_min_max = ((perc_app_families - np.min(perc_app_families)) /\n",
    "                             (np.max(perc_app_families) - np.min(perc_app_families)))\n",
    "\n",
    "balance_scores_min_max = ((balance_scores - np.min(balance_scores)) /\n",
    "                          (np.max(balance_scores) - np.min(balance_scores)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T13:46:09.715534832Z"
    }
   },
   "id": "b01b13bc1eba3662"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f_objective = perc_app_families_min_max + balance_scores_min_max\n",
    "t_split_mid = date_splits[np.argmax(f_objective)]\n",
    "print_statistics(df_dt, t_split_mid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T13:46:09.715655866Z"
    }
   },
   "id": "e178cd307000e15f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_splits = [t_split_min, t_split_mid, t_split_best]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T13:46:09.715770029Z"
    }
   },
   "id": "5c7a1a51dfcabf2a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for split in final_splits:\n",
    "\n",
    "    df_split = split_and_group(df_dt, df_dt[fsd] < split, df_dt.copy())\n",
    "    df_split[\"train_perc\"] = df_split[\"count\"] / 100\n",
    "    df_split[\"test_perc\"] = 1 - df_split[\"train_perc\"]\n",
    "    \n",
    "    df_split = df_split.sort_values(by=\"train_perc\", ascending=False)    \n",
    "    split_m = df_split[[\"train_perc\", \"test_perc\"]].to_numpy()\n",
    "\n",
    "    # Create a heatmap using seaborn\n",
    "    plt.figure(figsize=(6, 100))\n",
    "    sns.heatmap(split_m, annot=True, fmt=\".2f\",\n",
    "                          xticklabels=[\"Train %\", \"Test %\"], \n",
    "                          yticklabels=df_split[\"family\"])\n",
    "\n",
    "    plt.xlabel(\"Family\")\n",
    "    plt.ylabel(\"Split\")\n",
    "    plt.title(\"Heatmap Train-Test %\")\n",
    "    plt.savefig(f\"../doc/best_splits_img/split-{split}.png\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T13:46:09.715862304Z"
    }
   },
   "id": "2adf39155607239f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-11T13:46:09.716041318Z"
    }
   },
   "id": "17c8069c80dc7317"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "concept_drift",
   "language": "python",
   "display_name": "concept_drift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
