import gc
import os
import pandas as pd
from io import StringIO
from tqdm import tqdm

from src.feature_extraction import config


class MalwareDatasetBuilder:

    def __init__(self):
        self.__base_dir = os.path.dirname(os.path.abspath(__file__))

    @staticmethod
    def __build_sha_fsd_df(sha_fsd_file_path: str) -> pd.DataFrame:
        """
        Open VT reports and get SHA256 and first_submission_date values for each json (line).
        """
        malwares_first_sub_date = []
        with open(sha_fsd_file_path, 'r') as reports:
            sha256_key, first_sub_date_key = 'sha256', 'first_submission_date'
            # Iterate through all reports
            for report in reports:
                df_report = pd.read_json(StringIO(report))['data']['attributes']
                sha256, first_sub_date = df_report[sha256_key], df_report[first_sub_date_key]
                malwares_first_sub_date.append((sha256, first_sub_date))
        return pd.DataFrame(malwares_first_sub_date, columns=[sha256_key, first_sub_date_key])

    @staticmethod
    def __build_sha_family_df(malware_dir_path: str, min_samples: int = 100) -> pd.DataFrame:
        """
        Build dataset with malware's id (SHA256) and relative family columns
        """
        families = os.listdir(malware_dir_path)
        datasets = []
        for family in tqdm(families):
            current_samples = os.listdir(os.path.join(malware_dir_path, family))
            if len(current_samples) >= min_samples:
                family_dataset = pd.DataFrame({"sha256": current_samples, "family": family})
                datasets.append(family_dataset)
        df = pd.concat(datasets, ignore_index=True)
        return df

    def malware_family_fsd_df(self, vt_reports_path: str = None,
                              malware_dir_path: str = None,
                              min_samples: int = 100) -> pd.DataFrame:

        vt_reports_path = config.VT_REPORTS if vt_reports_path is None else vt_reports_path
        malware_dir_path = config.MALWARE_DIRECTORY if malware_dir_path is None else malware_dir_path
        merge_dataset_path = config.MERGE_DATASET_PATH

        if os.path.exists(merge_dataset_path):
            return pd.read_csv(merge_dataset_path, parse_dates=["first_submission_date"])
        else:
            df = pd.merge(left=self.__build_sha_family_df(malware_dir_path, min_samples),
                          right=self.__build_sha_fsd_df(vt_reports_path), on="sha256")
            # df.set_index("sha256", inplace=True)
            df["benign"] = False
            df["first_submission_date"] = (df["first_submission_date"]
                                           .apply(lambda t: pd.to_datetime(t, unit="s")))
            df.to_csv(merge_dataset_path, index=False)
            return df


class MalwareDataset:

    def __init__(self, split: pd.Timestamp):
        sha_exclude = [
            "351cd8d7048ce371d1f37e5eb12682ca395dee89fdd41b4cbea22cdf172fd768",  # neshta
            "d0e633203dca149fb61288f02f2225aab8d4d8058bd78dfc5e7a5c117213a57a",  # virfire
            "69b149169030e16ea2c49e738968676508923a89f4d81885d4c0acdffb1a5fd8",  # fakefire
            "59289c7b5708387a0ae898387219bb4b35f0ac3de155393bbaf191d48ddbacbe",  # fakefire
            "70c93baf8c128148b8f4997209ca6c83af9821237d44ee7fdbf190c99acacc0f",  # sabsik
            "dfa577d4b4f2d03231304711783f56059e49225c66c36a1fdd45d3234d4448f9",  # enosch
            "f74fd4a5b4428aae71cc7e6ca79379e9d11da7b69702997d8666437362258c40",  # kuluoz
        ]
        fsd = "first_submission_date"

        df_malware_family_fsd = MalwareDatasetBuilder().malware_family_fsd_df()
        self.df_malware_family_fsd = df_malware_family_fsd[~df_malware_family_fsd["sha256"].isin(sha_exclude)]
        training_dataset = self.df_malware_family_fsd[self.df_malware_family_fsd[fsd] < split]
        # Filter families with less than three samples
        counts = training_dataset.groupby("family").size().reset_index(name="size")
        counts = counts[counts["size"] > 3]
        self.training_dataset = training_dataset[training_dataset["family"].isin(counts["family"])]
        # self.testing_dataset = self.df_malware_family_fsd[self.df_malware_family_fsd[fsd] >= split]